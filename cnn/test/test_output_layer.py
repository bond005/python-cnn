# -*- coding: utf-8 -*-
#
# Скрипт ориентирован на использование в Python 3.*
# Все данные и расчёты, используемые в позитивных тестах, приведены в гуглодоке:
# https://docs.google.com/spreadsheets/d/1KXuLShbVoL2kaRFOCbTMkS-BNMuc3xVwZA8HwAuShno/edit?usp=sharing
#

import copy
import os
import random
import sys
import numpy
import unittest

cnn_package_path = os.path.split(os.path.split(os.getcwd())[0])[0]
sys.path.append(cnn_package_path)
from cnn import output_layer
from cnn.common import integer_to_ordinal

class TestOutputLayer(unittest.TestCase):
    def setUp(self):
        self.__epsilon = 0.000001
        random.seed()
        numpy.random.seed()
        self.__layer_id = 1
        self.__number_of_input_maps = 3
        self.__input_map_size = (6, 5)
        self.__input_maps = [
            numpy.array([
                (-0.14062, 0.293809, 0.905852, -0.45878, 0.740724),
                (-0.68267, -0.09463, 0.614261, -0.50213, 0.565014),
                (0.076374, -0.7649, -0.30093, 0.471437, -0.32848),
                (-0.38347, 0.160011, -0.30884, 0.493158, -0.28132),
                (-0.64146, -0.92638, 0.867563, -0.10696, -0.05661),
                (0.422351, -0.06871, 0.186391, -0.49686, 0.870728)
            ]),
            numpy.array([
                (-0.20349, 0.031203, -0.12173, 0.743632, 0.328677),
                (-0.20938, 0.00954, 0.517926, 0.607911, 0.535574),
                (0.808547, 0.074892, -0.54315, -0.34995, 0.639988),
                (0.773657, -0.29811, -0.13906, -0.51, -0.00329),
                (-0.27878, 0.498802, -0.15015, 0.823873, 0.800871),
                (0.100963, 0.540328, -0.4175, -0.13177, 0.149454)
            ]),
            numpy.array([
                (-0.79188, 0.276618, -0.43735, -0.72712, -0.85333),
                (-0.63524, -0.39295, 0.667738, -0.7939, 0.728149),
                (-0.7309, 0.15348, -0.78023, -0.05637, -0.56361),
                (-0.02899, 0.209677, 0.162097, 0.481749, 0.270865),
                (-0.92895, 0.193228, -0.10883, 0.21654, -0.25176),
                (-0.62173, -0.15969, 0.700956, 0.87735, 0.450899)
            ])
        ]
        self.__number_of_neurons = 5
        self.__weights_before_learning = [
            [
                numpy.array([
                    (-0.454674414, -0.441725273, -0.486623893, -0.376976411, 0.367468698),
                    (-0.053292873, 0.326160682, 0.326991651, 0.202840349, -0.422132417),
                    (-0.445360747, -0.449640024, -0.406142867, -0.003760607, -0.482318478),
                    (-0.253001885, 0.102090174, 0.246324147, 0.481517294, -0.361479527),
                    (-0.450400576, 0.006689988, -0.333592, 0.426673298, -0.280534841),
                    (-0.065965359, -0.398088238, -0.490655182, 0.171313846, 0.264480646)
                ]),
                numpy.array([
                    (0.079794328, -0.19524951, 0.317091302, -0.459675767, -0.198357636),
                    (-0.480168326, -0.392917773, -0.23172113, -0.00792253, 0.070097674),
                    (0.405826162, 0.197388915, 0.4789901, 0.420279572, -0.159391308),
                    (0.372226375, -0.372530989, 0.145719222, 0.018017577, 0.251069434),
                    (0.217568815, -0.148776829, 0.001326967, -0.130171852, 0.369767726),
                    (-0.341117794, 0.145898972, -0.332775521, 0.483934177, -0.416705353)
                ]),
                numpy.array([
                    (-0.476924909, -0.269225488, -0.249753236, -0.442314854, -0.159383912),
                    (-0.323957971, 0.195592978, 0.422373795, 0.060914007, 0.062989159),
                    (0.292780167, 0.279683882, 0.444263032, -0.438587034, 0.135713465),
                    (0.377193973, 0.016155193, -0.459097708, 0.266688111, -0.220697964),
                    (-0.362538178, -0.011432353, -0.27093209, -0.248956626, 0.07696188),
                    (-0.047400263, -0.062470349, 0.078586347, 0.27625016, 0.18835347)
                ])
            ],
            [
                numpy.array([
                    (-0.202863282, 0.28829226, 0.282718135, 0.096134406, 0.456977996),
                    (-0.274418228, -0.234425706, 0.05785365, -0.06490379, -0.377486742),
                    (-0.419559302, -0.143778663, -0.116099926, -0.474383738, 0.046602598),
                    (0.044930093, 0.247712139, 0.005803541, 0.250998176, 0.449352095),
                    (0.199603456, -0.07557929, 0.322262488, -0.359220075, 0.245747417),
                    (0.014741504, 0.238926459, 0.491132787, 0.276878266, -0.137662576)
                ]),
                numpy.array([
                    (0.490487156, 0.005511377, -0.014476584, 0.228535976, -0.393549441),
                    (0.189291725, -0.327867206, 0.092874804, -0.049892357, 0.279776564),
                    (-0.276009354, 0.290751897, 0.348271842, -0.377064422, 0.478562769),
                    (-0.343580366, 0.298695006, 0.286017776, -0.457108345, 0.238568862),
                    (-0.292281832, -0.46288513, 0.230249426, 0.288571429, 0.028275002),
                    (0.145991153, 0.404859449, 0.066038543, 0.156398111, 0.145153439)
                ]),
                numpy.array([
                    (0.463882371, -0.311133241, 0.372956677, -0.098991783, -0.049545014),
                    (-0.284782393, 0.431144666, 0.291606315, 0.498025137, 0.335957571),
                    (-0.204876622, -0.31305411, 0.417761697, -0.015632546, -0.003135778),
                    (0.034053238, -0.35497037, -0.44041787, -0.092747184, -0.109488222),
                    (-0.114606532, 0.069268646, -0.39206122, -0.045330931, 0.155447554),
                    (0.338865244, 0.113643134, -0.057939344, -0.379042147, 0.21078928)
                ])
            ],
            [
                numpy.array([
                    (-0.299678495, -0.113090667, -0.18903115, -0.184299415, -0.371188011),
                    (-0.494101227, -0.258069743, -0.299069225, 0.273435785, -0.142228124),
                    (-0.000329091, -0.153832775, 0.395297859, -0.186692651, 0.353874482),
                    (-0.447242771, 0.018163554, -0.078206526, -0.266116927, -0.299481678),
                    (0.032140557, -0.283720287, -0.194573184, -0.186307706, -0.191749879),
                    (-0.183227743, 0.039593093, 0.455484617, 0.021098511, 0.098095268)
                ]),
                numpy.array([
                    (-0.311148519, -0.194404053, 0.323847546, 0.364637794, -0.280976444),
                    (0.188403093, -0.374352309, 0.269344625, 0.499948284, -0.276370449),
                    (-0.295358328, -0.24729578, -0.217795888, -0.335376398, 0.335477232),
                    (0.331628197, -0.209947528, -0.077432699, -0.136797804, -0.289596848),
                    (0.139455282, -0.180101284, 0.306369567, 0.15976188, -0.47032822),
                    (0.446516761, 0.33013828, -0.360802439, -0.47452184, -0.295809218)
                ]),
                numpy.array([
                    (0.369013813, 0.477380155, -0.452500277, 0.438185997, 0.426058596),
                    (-0.242282214, -0.260105689, 0.154901667, -0.028947964, 0.065422646),
                    (-0.253542557, -0.317212602, -0.432593688, -0.334732307, -0.192623597),
                    (-0.440837817, -0.356527346, 0.116265104, -0.126445104, -0.274360094),
                    (0.29171755, -0.276353739, 0.137749256, 0.118710131, -0.484571369),
                    (-0.322392575, -0.386873394, -0.361833835, -0.255350275, -0.349296533)
                ])
            ],
            [
                numpy.array([
                    (-0.449460745, -0.253007887, -0.194399328, -0.275367064, -0.359070774),
                    (-0.34433586, -0.012106807, -0.129307274, -0.139861178, -0.136041697),
                    (-0.005309823, -0.196891443, -0.048109688, 0.272980185, 0.061122833),
                    (-0.421634952, 0.486388495, -0.229163475, 0.00103553, 0.476910662),
                    (0.29657942, 0.457293363, -0.167292721, 0.11759179, -0.21235073),
                    (-0.097914524, -0.160020185, -0.072404522, 0.160948139, -0.478466397)
                ]),
                numpy.array([
                    (-0.420607506, 0.172098881, -0.376769741, -0.366272162, -0.293564716),
                    (-0.464811374, -0.402434773, 0.109630806, 0.263349757, 0.129296024),
                    (-0.054035277, -0.067294919, -0.264539027, -0.332085643, -0.338287466),
                    (-0.268050896, 0.445170539, -0.407633996, -0.124971714, -0.0072076),
                    (-0.384147329, 0.419084917, -0.076962926, 0.187870538, 0.021116395),
                    (-0.112073712, 0.263373415, -0.085608985, -0.457872067, 0.006026119)
                ]),
                numpy.array([
                    (-0.035959159, 0.419720805, 0.124757543, 0.035578072, 0.189412826),
                    (-0.38675052, 0.452691094, -0.464881311, -0.408597675, 0.188096728),
                    (-0.023559184, -0.443554656, 0.364865831, -0.061112865, -0.116008117),
                    (0.358103596, -0.085526332, 0.014058369, -0.339390463, -0.16219448),
                    (-0.173262608, 0.046314698, -0.41004383, -0.165248266, 0.012242206),
                    (-0.099145536, 0.451810915, 0.328634, 0.340084647, 0.461833215)
                ])
            ],
            [
                numpy.array([
                    (0.124252122, 0.292495015, -0.224113444, -0.256014028, -0.387348048),
                    (-0.341058309, -0.333722667, 0.048620384, -0.370189773, 0.422851122),
                    (0.224746715, -0.138544677, -0.159919879, 0.110663154, -0.258574362),
                    (0.070696506, 0.462299485, -0.447285126, 0.464142036, -0.160356366),
                    (0.429070791, 0.46824914, 0.344677839, 0.236996919, 0.412389438),
                    (-0.003488852, 0.119097804, -0.152228698, -0.271103595, -0.33506325)
                ]),
                numpy.array([
                    (-0.27142832, -0.186759268, 0.162263413, 0.234338668, 0.442739308),
                    (-0.232565198, 0.127096043, -0.478007937, 0.314343831, 0.139751638),
                    (-0.030116727, 0.449512681, -0.337397043, -0.439935018, 0.228024253),
                    (-0.043690428, -0.010719449, -0.444858394, -0.241143995, -0.149188489),
                    (-0.187198303, 0.095820806, -0.221517029, 0.219883989, 0.378959773),
                    (0.387755985, -0.367029968, 0.225137997, 0.312546061, 0.013971877)
                ]),
                numpy.array([
                    (-0.167213155, 0.419868757, -0.284917038, 0.02046365, -0.053330047),
                    (-0.357636875, 0.261632758, 0.230166954, 0.111422782, 0.314619794),
                    (-0.269418538, 0.15532752, 0.036454943, 0.40769268, 0.226733427),
                    (-0.1884218, 0.310495793, -0.236800472, -0.034481034, 0.052192425),
                    (0.246573096, -0.063274796, 0.252527381, -0.261363721, 0.466122399),
                    (0.381547041, -0.291036933, 0.389778391, 0.287433182, 0.27758928)
                ])
            ]
        ]
        self.__biases_before_learning = [-0.39984, 0.329791, 0.481977, -0.1092, 0.360864]
        self.__target_real_outputs = [0.1534370585, 0.02868515884, 0.07098075628, 0.03057882823, 0.7163181981]
        self.__target_target_outputs = [0.0, 0.0, 0.0, 0.0, 1.0]
        self.__target_gradients = [-0.1534370585, -0.02868515884, -0.07098075628, -0.03057882823, 0.2836818019]
        self.__learning_rate = 1.0
        self.__weights_after_learning = [
            [
                numpy.array([
                    (-0.4330980948, -0.4868064617, -0.6256151593, -0.3065825573, 0.2538141863),
                    (0.05145400374, 0.3406804308, 0.23274125, 0.2798856992, -0.5088265032),
                    (-0.4570793489, -0.3322760179, -0.359969053, -0.07609651356, -0.431917473),
                    (-0.1941633762, 0.07753855683, 0.2937116482, 0.4058485811, -0.3183146137),
                    (-0.3519768404, 0.1488310103, -0.4667083148, 0.4430849258, -0.2718487691),
                    (-0.1307696541, -0.3875455777, -0.5192544688, 0.2475505829, 0.1308787029)
                ]),
                numpy.array([
                    (0.111017235, -0.2000372065, 0.3357691951, -0.5737764737, -0.2487888681),
                    (-0.4480416747, -0.3943815625, -0.311190172, -0.1011986057, -0.01207922518),
                    (0.2817650886, 0.1858977068, 0.5623294383, 0.4739748706, -0.2575891842),
                    (0.2535187206, -0.3267898675, 0.1670561794, 0.09627047684, 0.2515742419),
                    (0.2603439982, -0.2253115407, 0.02436554134, -0.2565845017, 0.2468844355),
                    (-0.3566092597, 0.06299263304, -0.2687155491, 0.5041525782, -0.4396371351)
                ]),
                numpy.array([
                    (-0.3554211711, -0.3116689403, -0.1826475385, -0.3307477, -0.02845146685),
                    (-0.2264886139, 0.2558860701, 0.3199180404, 0.1827276878, -0.04873588172),
                    (0.4049273131, 0.2561343623, 0.5639792282, -0.429937787, 0.2221921256),
                    (0.3816421133, -0.01601702912, -0.4839693949, 0.1927699615, -0.2622586929),
                    (-0.2200028225, -0.04108068894, -0.2542335349, -0.2821818867, 0.1155911939),
                    (0.04799615939, -0.03796798513, -0.02896627979, 0.1416321567, 0.1191688538)
                ])
            ],
            [
                numpy.array([
                    (-0.198829575, 0.2798643022, 0.2567336265, 0.1092945832, 0.4357302104),
                    (-0.2548357306, -0.2317112294, 0.04023347564, -0.05050011119, -0.3936942583),
                    (-0.4217501023, -0.121837385, -0.1074677011, -0.4879069832, 0.05602509898),
                    (0.05592999086, 0.243122198, 0.01466266546, 0.2368518604, 0.4574218039),
                    (0.218003838, -0.04900593255, 0.2973763055, -0.3561519104, 0.2473712838),
                    (0.002626298477, 0.2408974163, 0.4857861316, 0.291130774, -0.162639547)
                ]),
                numpy.array([
                    (0.496324299, 0.004616313989, -0.01098473961, 0.207204774, -0.402977593),
                    (0.1952978236, -0.3281408624, 0.07801801442, -0.0673303806, 0.2644135387),
                    (-0.2992026531, 0.2886036081, 0.363852186, -0.3670260507, 0.4602046116),
                    (-0.3657728399, 0.3072463387, 0.2900067342, -0.442478914, 0.2386632362),
                    (-0.2842849834, -0.4771933446, 0.2345565026, 0.2649385011, 0.005301890151),
                    (0.1430950133, 0.3893600545, 0.07801459682, 0.1601779544, 0.1408663273)
                ]),
                numpy.array([
                    (0.4865975746, -0.3190680723, 0.3855021312, -0.0781342303, -0.0250671074),
                    (-0.2665604327, 0.4424164992, 0.2724521444, 0.5207982846, 0.3150705013),
                    (-0.1839106394, -0.3174567082, 0.4401427185, -0.0140155636, 0.01303146438),
                    (0.03488482075, -0.3609849881, -0.4450676482, -0.1065662306, -0.1172580276),
                    (-0.08795945369, 0.06372587013, -0.3889394142, -0.0515424153, 0.1626693296),
                    (0.3566996678, 0.118223867, -0.0780463782, -0.4042090711, 0.1978551706)
                ])
            ],
            [
                numpy.array([
                    (-0.2896971811, -0.133945452, -0.25332921, -0.1517348636, -0.4237651607),
                    (-0.4456447941, -0.251352834, -0.3426699353, 0.3090773521, -0.182333245),
                    (-0.00575017528, -0.09953959452, 0.416658098, -0.2201556058, 0.3771902408),
                    (-0.4200237804, 0.006805852207, -0.05628482923, -0.3011216548, -0.2795133716),
                    (0.07767187292, -0.217965134, -0.2561534619, -0.1787156043, -0.1877316584),
                    (-0.2132065364, 0.04447018076, 0.4422544429, 0.05636600956, 0.03629033605)
                ]),
                numpy.array([
                    (-0.2967046449, -0.1966188655, 0.3324880335, 0.3118542322, -0.304306186),
                    (0.2032650437, -0.3750294654, 0.2325818458, 0.4567983015, -0.3143858966),
                    (-0.3527496055, -0.2526116708, -0.1792426902, -0.3105366823, 0.2900503998),
                    (0.276713438, -0.1887874547, -0.06756211503, -0.1005976183, -0.2893633213),
                    (0.1592432972, -0.2155066272, 0.3170273276, 0.1012827514, -0.5271746493),
                    (0.4393503309, 0.2917853899, -0.3311679733, -0.4651687057, -0.3064175759)
                ]),
                numpy.array([
                    (0.4252220543, 0.4577456002, -0.4214568432, 0.4897975245, 0.4866286048),
                    (-0.1971923984, -0.2322138008, 0.1075051188, 0.02740365841, 0.0137380793),
                    (-0.2016627222, -0.3281067285, -0.3772123725, -0.3307311218, -0.152618133),
                    (-0.4387800849, -0.371410378, 0.1047593363, -0.1606400124, -0.2935862965),
                    (0.3576551235, -0.2900692086, 0.1454740917, 0.103339958, -0.4667012538),
                    (-0.2782617094, -0.375538477, -0.411588222, -0.3176252415, -0.381301685)
                ])
            ],
            [
                numpy.array([
                    (-0.4451607502, -0.2619922219, -0.2220992207, -0.2613381092, -0.381721246),
                    (-0.3234606113, -0.009213132485, -0.1480906556, -0.124506631, -0.1533191631),
                    (-0.007645250427, -0.1735016973, -0.03890760122, 0.258564194, 0.0711673665),
                    (-0.4099088887, 0.4814955461, -0.2197195097, -0.01404466377, 0.485513098),
                    (0.3161945152, 0.4856209779, -0.193821781, 0.1208625015, -0.2106196625),
                    (-0.1108295227, -0.1579191137, -0.07810414037, 0.1761415356, -0.5050922389)
                ]),
                numpy.array([
                    (-0.4143850202, 0.1711447298, -0.3730473802, -0.3890115572, -0.3036152735),
                    (-0.4584087789, -0.402726495, 0.09379323581, 0.244760551, 0.1129187987),
                    (-0.07875969683, -0.0695850286, -0.2479301364, -0.3213845821, -0.3578575491),
                    (-0.2917084205, 0.4542863935, -0.4033817041, -0.1093765116, -0.007106995655),
                    (-0.3756225633, 0.4038321363, -0.07237151494, 0.1626774671, -0.003373301742),
                    (-0.1151610422, 0.2468508179, -0.07284232421, -0.4538426948, 0.001455990806)
                ]),
                numpy.array([
                    (-0.0117443965, 0.4112621507, 0.1381311935, 0.05781254958, 0.2155066575),
                    (-0.3673256252, 0.4647070446, -0.4852999566, -0.3843211433, 0.1658307848),
                    (-0.001209118448, -0.4482478946, 0.3887243501, -0.05938913645, -0.09877358362),
                    (0.3589900762, -0.09193800897, 0.009101632681, -0.3541217829, -0.1704772143),
                    (-0.1448564055, 0.04040601218, -0.4067159361, -0.1718698055, 0.01994073179),
                    (-0.08013376113, 0.4566940481, 0.3071995869, 0.3132563121, 0.4480452519)
                ])
            ],
            [
                numpy.array([
                    (0.08436078702, 0.3758432815, 0.03286028359, -0.3861615651, -0.177218129),
                    (-0.5347193647, -0.3605674759, 0.2228750513, -0.5126349162, 0.5831353116),
                    (0.2464126289, -0.3555328873, -0.2452882436, 0.2444012516, -0.3517581603),
                    (-0.03808695456, 0.5076916938, -0.5348974137, 0.604041986, -0.2401617305),
                    (0.2471002624, 0.2054519924, 0.5907896741, 0.2066543135, 0.3963302112),
                    (0.1163244407, 0.09960602739, -0.09935296327, -0.4120537351, -0.08805356202)
                ]),
                numpy.array([
                    (-0.3291547299, -0.1779075447, 0.1277308273, 0.4452935337, 0.5359789916),
                    (-0.2919624937, 0.1298023674, -0.3310817561, 0.4867971189, 0.2916842354),
                    (0.1992533429, 0.4707581785, -0.4914788137, -0.5392094646, 0.409577202),
                    (0.1757819838, -0.09528783096, -0.4843071854, -0.385821714, -0.1501218021),
                    (-0.2662831157, 0.2373218561, -0.2641118516, 0.4536017662, 0.6061523013),
                    (0.4163973508, -0.2137487474, 0.1067008447, 0.27516531, 0.05636925702)
                ]),
                numpy.array([
                    (-0.3918551003, 0.4983402497, -0.408985274, -0.1858070618, -0.295404239),
                    (-0.5378429028, 0.150159994, 0.419592073, -0.1137922005, 0.5211824143),
                    (-0.476761567, 0.198867003, -0.1848821093, 0.3917015368, 0.06684752665),
                    (-0.1966457354, 0.3699773422, -0.190816503, 0.1021823904, 0.1290318963),
                    (-0.01695311385, -0.008459528788, 0.2216542905, -0.1999352636, 0.3947026686),
                    (0.2051735543, -0.3363380799, 0.5886268521, 0.5363214109, 0.4055011208)
                ])
            ]
        ]
        self.__biases_after_learning = [-0.5532770585, 0.3011058412, 0.4109962437, -0.1397788282, 0.6445458019]
        self.__outp_layer = output_layer.OutputLayer(
            self.__layer_id,
            self.__number_of_input_maps,
            self.__input_map_size,
            self.__number_of_neurons
        )

    def __same_weights_and_biases(self, old_weights, old_biases, new_weights, new_biases):
        is_same = True
        if len(old_weights) == len(new_weights):
            for ft_ind in range(len(old_weights)):
                if len(old_weights[ft_ind]) != len(new_weights[ft_ind]):
                    is_same = False
                else:
                    for inp_ind in range(len(old_weights[ft_ind])):
                        if not isinstance(old_weights[ft_ind][inp_ind], numpy.ndarray):
                            is_same = False
                            break
                        if not isinstance(new_weights[ft_ind][inp_ind], numpy.ndarray):
                            is_same = False
                            break
                        if old_weights[ft_ind][inp_ind].shape != new_weights[ft_ind][inp_ind].shape:
                            is_same = False
                            break
                        for ind in numpy.ndindex(old_weights[ft_ind][inp_ind].shape):
                            deviation = abs(old_weights[ft_ind][inp_ind][ind]\
                                            - new_weights[ft_ind][inp_ind][ind])
                            if deviation > self.__epsilon:
                                is_same = False
                                break
                        if not is_same:
                            break
                if not is_same:
                    break
        else:
            is_same = False
        if is_same:
            if len(old_biases) == len(new_biases):
                for ft_ind in range(len(old_biases)):
                    if abs(old_biases[ft_ind] - new_biases[ft_ind]) > self.__epsilon:
                        is_same = False
                        break
            else:
                is_same = False
        return is_same

    def __initialize_weights_and_biases(self):
        repeats = 0
        is_same = True
        while is_same and (repeats < 10):
            self.__outp_layer.initialize_weights_and_biases()
            is_same = self.__same_weights_and_biases(
                self.__outp_layer.weights, self.__outp_layer.biases,
                self.__weights_before_learning, self.__biases_before_learning
            )
            repeats += 1
        return not is_same

    def test_weights_and_biases_test_positive_1(self):
        """ Проверить, как записываются и читаются свойства weights ('Веса') и biases
        ('Смещения'). """
        self.assertTrue(self.__initialize_weights_and_biases(),
                        msg = 'Weights and biases of output layer cannot be initialized!')
        self.__outp_layer.weights = self.__weights_before_learning
        self.__outp_layer.biases = self.__biases_before_learning
        new_weights = self.__outp_layer.weights
        self.assertEqual(len(new_weights), self.__number_of_neurons,
                         msg = 'Target {0} != real {1}: number of neurons with '\
                         'convolution kernels is incorrect!'.format(self.__number_of_neurons,
                                                                    len(new_weights))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertEqual(len(new_weights[neuron_ind]), self.__number_of_input_maps,
                             msg = 'Target {0} != real {1}: number of convolution kernels '\
                             'of {2} neuron is incorrect!'.format(
                                 self.__number_of_input_maps, len(new_weights[neuron_ind]),
                                 integer_to_ordinal(neuron_ind+1))
                             )
            for inp_ind in range(self.__number_of_input_maps):
                self.assertIsInstance(new_weights[neuron_ind][inp_ind], numpy.ndarray,
                                      msg = 'Type of {0} convolution kernel of {1} neuron is '\
                                      'incorrect!'.format(integer_to_ordinal(inp_ind+1),
                                                          integer_to_ordinal(neuron_ind+1))
                                      )
                self.assertEqual(new_weights[neuron_ind][inp_ind].shape, self.__input_map_size,
                                 msg = 'Sizes of {0} convolution kernel of {1} neuron are '\
                                 'incorrect!'.format(integer_to_ordinal(inp_ind+1),
                                                     integer_to_ordinal(neuron_ind+1))
                                 )
                for ind in numpy.ndindex(self.__input_map_size):
                    self.assertAlmostEqual(
                        new_weights[neuron_ind][inp_ind][ind],
                        self.__weights_before_learning[neuron_ind][inp_ind][ind],
                        msg = 'Values of {0} convolution kernel of {1} neuron are '\
                        'incorrect!\n{2}'.format(
                            integer_to_ordinal(inp_ind+1), integer_to_ordinal(neuron_ind+1),
                            str(new_weights[neuron_ind][inp_ind]))
                    )
        new_biases = self.__outp_layer.biases
        self.assertEqual(len(new_biases), self.__number_of_neurons,
                         msg = 'Target {0} != real {1}: number of neurons with '\
                         'biases is incorrect!'.format(self.__number_of_neurons,
                                                       len(new_biases))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertIsInstance(new_biases[neuron_ind], float,
                                  msg = 'Type of {0} neuron\'s bias is incorrect'.format(
                                      integer_to_ordinal(neuron_ind+1))
                                  )
            self.assertAlmostEqual(
                new_biases[neuron_ind], self.__biases_before_learning[neuron_ind],
                msg = 'Target {0} != real {1}: value of {2} neuron\'s bias is '\
                'incorrect'.format(self.__biases_before_learning[neuron_ind],
                                   new_biases[neuron_ind], integer_to_ordinal(neuron_ind+1)
                                   )
                )

    def test_weights_test_negative_1(self):
        """ Веса слоя - это список списков NumPy-матриц. Проверить ситуацию, когда вместо этого
        на вход свойства weights подаётся какой-то отфонарный список списков вещественных чисел. """
        new_weights = [[[[random.random() for col_ind in range(self.__input_map_size[1])] \
                         for row_ind in range(self.__input_map_size[0])] \
                        for inp_ind in range(self.__number_of_input_maps)] \
                       for neuron_ind in range(self.__number_of_neurons)]
        with self.assertRaises(TypeError):
            self.__outp_layer.weights = new_weights

    def test_weights_test_negative_2(self):
        """ Веса слоя - это список списков NumPy-матриц (количество нейронов - количество входных
        карт - матрицы ядер свёртки). Проверить ситуацию, когда по количеству нейронов и количеству
        входных карт всё ок, а вот NumPy-матрицы не соответствуют ожидаемым ядрам свёртки по
        размерам. """
        new_weights = [
            [
                numpy.array([
                    (-0.454674414, -0.441725273, -0.486623893, -0.376976411, 0.367468698, 0.0),
                    (-0.053292873, 0.326160682, 0.326991651, 0.202840349, -0.422132417, 0.0),
                    (-0.445360747, -0.449640024, -0.406142867, -0.003760607, -0.482318478, 0.0),
                    (-0.253001885, 0.102090174, 0.246324147, 0.481517294, -0.361479527, 0.0),
                    (-0.450400576, 0.006689988, -0.333592, 0.426673298, -0.280534841, 0.0),
                    (-0.065965359, -0.398088238, -0.490655182, 0.171313846, 0.264480646, 0.0)
                ]),
                numpy.array([
                    (0.079794328, -0.19524951, 0.317091302, -0.459675767, -0.198357636, 0.0),
                    (-0.480168326, -0.392917773, -0.23172113, -0.00792253, 0.070097674, 0.0),
                    (0.405826162, 0.197388915, 0.4789901, 0.420279572, -0.159391308, 0.0),
                    (0.372226375, -0.372530989, 0.145719222, 0.018017577, 0.251069434, 0.0),
                    (0.217568815, -0.148776829, 0.001326967, -0.130171852, 0.369767726, 0.0),
                    (-0.341117794, 0.145898972, -0.332775521, 0.483934177, -0.416705353, 0.0)
                ]),
                numpy.array([
                    (-0.476924909, -0.269225488, -0.249753236, -0.442314854, -0.159383912, 0.0),
                    (-0.323957971, 0.195592978, 0.422373795, 0.060914007, 0.062989159, 0.0),
                    (0.292780167, 0.279683882, 0.444263032, -0.438587034, 0.135713465, 0.0),
                    (0.377193973, 0.016155193, -0.459097708, 0.266688111, -0.220697964, 0.0),
                    (-0.362538178, -0.011432353, -0.27093209, -0.248956626, 0.07696188, 0.0),
                    (-0.047400263, -0.062470349, 0.078586347, 0.27625016, 0.18835347, 0.0)
                ])
            ],
            [
                numpy.array([
                    (-0.202863282, 0.28829226, 0.282718135, 0.096134406, 0.456977996, 0.0),
                    (-0.274418228, -0.234425706, 0.05785365, -0.06490379, -0.377486742, 0.0),
                    (-0.419559302, -0.143778663, -0.116099926, -0.474383738, 0.046602598, 0.0),
                    (0.044930093, 0.247712139, 0.005803541, 0.250998176, 0.449352095, 0.0),
                    (0.199603456, -0.07557929, 0.322262488, -0.359220075, 0.245747417, 0.0),
                    (0.014741504, 0.238926459, 0.491132787, 0.276878266, -0.137662576, 0.0)
                ]),
                numpy.array([
                    (0.490487156, 0.005511377, -0.014476584, 0.228535976, -0.393549441, 0.0),
                    (0.189291725, -0.327867206, 0.092874804, -0.049892357, 0.279776564, 0.0),
                    (-0.276009354, 0.290751897, 0.348271842, -0.377064422, 0.478562769, 0.0),
                    (-0.343580366, 0.298695006, 0.286017776, -0.457108345, 0.238568862, 0.0),
                    (-0.292281832, -0.46288513, 0.230249426, 0.288571429, 0.028275002, 0.0),
                    (0.145991153, 0.404859449, 0.066038543, 0.156398111, 0.145153439, 0.0)
                ]),
                numpy.array([
                    (0.463882371, -0.311133241, 0.372956677, -0.098991783, -0.049545014, 0.0),
                    (-0.284782393, 0.431144666, 0.291606315, 0.498025137, 0.335957571, 0.0),
                    (-0.204876622, -0.31305411, 0.417761697, -0.015632546, -0.003135778, 0.0),
                    (0.034053238, -0.35497037, -0.44041787, -0.092747184, -0.109488222, 0.0),
                    (-0.114606532, 0.069268646, -0.39206122, -0.045330931, 0.155447554, 0.0),
                    (0.338865244, 0.113643134, -0.057939344, -0.379042147, 0.21078928, 0.0)
                ])
            ],
            [
                numpy.array([
                    (-0.299678495, -0.113090667, -0.18903115, -0.184299415, -0.371188011, 0.0),
                    (-0.494101227, -0.258069743, -0.299069225, 0.273435785, -0.142228124, 0.0),
                    (-0.000329091, -0.153832775, 0.395297859, -0.186692651, 0.353874482, 0.0),
                    (-0.447242771, 0.018163554, -0.078206526, -0.266116927, -0.299481678, 0.0),
                    (0.032140557, -0.283720287, -0.194573184, -0.186307706, -0.191749879, 0.0),
                    (-0.183227743, 0.039593093, 0.455484617, 0.021098511, 0.098095268, 0.0)
                ]),
                numpy.array([
                    (-0.311148519, -0.194404053, 0.323847546, 0.364637794, -0.280976444, 0.0),
                    (0.188403093, -0.374352309, 0.269344625, 0.499948284, -0.276370449, 0.0),
                    (-0.295358328, -0.24729578, -0.217795888, -0.335376398, 0.335477232, 0.0),
                    (0.331628197, -0.209947528, -0.077432699, -0.136797804, -0.289596848, 0.0),
                    (0.139455282, -0.180101284, 0.306369567, 0.15976188, -0.47032822, 0.0),
                    (0.446516761, 0.33013828, -0.360802439, -0.47452184, -0.295809218, 0.0)
                ]),
                numpy.array([
                    (0.369013813, 0.477380155, -0.452500277, 0.438185997, 0.426058596, 0.0),
                    (-0.242282214, -0.260105689, 0.154901667, -0.028947964, 0.065422646, 0.0),
                    (-0.253542557, -0.317212602, -0.432593688, -0.334732307, -0.192623597, 0.0),
                    (-0.440837817, -0.356527346, 0.116265104, -0.126445104, -0.274360094, 0.0),
                    (0.29171755, -0.276353739, 0.137749256, 0.118710131, -0.484571369, 0.0),
                    (-0.322392575, -0.386873394, -0.361833835, -0.255350275, -0.349296533, 0.0)
                ])
            ],
            [
                numpy.array([
                    (-0.449460745, -0.253007887, -0.194399328, -0.275367064, -0.359070774, 0.0),
                    (-0.34433586, -0.012106807, -0.129307274, -0.139861178, -0.136041697, 0.0),
                    (-0.005309823, -0.196891443, -0.048109688, 0.272980185, 0.061122833, 0.0),
                    (-0.421634952, 0.486388495, -0.229163475, 0.00103553, 0.476910662, 0.0),
                    (0.29657942, 0.457293363, -0.167292721, 0.11759179, -0.21235073, 0.0),
                    (-0.097914524, -0.160020185, -0.072404522, 0.160948139, -0.478466397, 0.0)
                ]),
                numpy.array([
                    (-0.420607506, 0.172098881, -0.376769741, -0.366272162, -0.293564716, 0.0),
                    (-0.464811374, -0.402434773, 0.109630806, 0.263349757, 0.129296024, 0.0),
                    (-0.054035277, -0.067294919, -0.264539027, -0.332085643, -0.338287466, 0.0),
                    (-0.268050896, 0.445170539, -0.407633996, -0.124971714, -0.0072076, 0.0),
                    (-0.384147329, 0.419084917, -0.076962926, 0.187870538, 0.021116395, 0.0),
                    (-0.112073712, 0.263373415, -0.085608985, -0.457872067, 0.006026119, 0.0)
                ]),
                numpy.array([
                    (-0.035959159, 0.419720805, 0.124757543, 0.035578072, 0.189412826, 0.0),
                    (-0.38675052, 0.452691094, -0.464881311, -0.408597675, 0.188096728, 0.0),
                    (-0.023559184, -0.443554656, 0.364865831, -0.061112865, -0.116008117, 0.0),
                    (0.358103596, -0.085526332, 0.014058369, -0.339390463, -0.16219448, 0.0),
                    (-0.173262608, 0.046314698, -0.41004383, -0.165248266, 0.012242206, 0.0),
                    (-0.099145536, 0.451810915, 0.328634, 0.340084647, 0.461833215, 0.0)
                ])
            ],
            [
                numpy.array([
                    (0.124252122, 0.292495015, -0.224113444, -0.256014028, -0.387348048, 0.0),
                    (-0.341058309, -0.333722667, 0.048620384, -0.370189773, 0.422851122, 0.0),
                    (0.224746715, -0.138544677, -0.159919879, 0.110663154, -0.258574362, 0.0),
                    (0.070696506, 0.462299485, -0.447285126, 0.464142036, -0.160356366, 0.0),
                    (0.429070791, 0.46824914, 0.344677839, 0.236996919, 0.412389438, 0.0),
                    (-0.003488852, 0.119097804, -0.152228698, -0.271103595, -0.33506325, 0.0)
                ]),
                numpy.array([
                    (-0.27142832, -0.186759268, 0.162263413, 0.234338668, 0.442739308, 0.0),
                    (-0.232565198, 0.127096043, -0.478007937, 0.314343831, 0.139751638, 0.0),
                    (-0.030116727, 0.449512681, -0.337397043, -0.439935018, 0.228024253, 0.0),
                    (-0.043690428, -0.010719449, -0.444858394, -0.241143995, -0.149188489, 0.0),
                    (-0.187198303, 0.095820806, -0.221517029, 0.219883989, 0.378959773, 0.0),
                    (0.387755985, -0.367029968, 0.225137997, 0.312546061, 0.013971877, 0.0)
                ]),
                numpy.array([
                    (-0.167213155, 0.419868757, -0.284917038, 0.02046365, -0.053330047, 0.0),
                    (-0.357636875, 0.261632758, 0.230166954, 0.111422782, 0.314619794, 0.0),
                    (-0.269418538, 0.15532752, 0.036454943, 0.40769268, 0.226733427, 0.0),
                    (-0.1884218, 0.310495793, -0.236800472, -0.034481034, 0.052192425, 0.0),
                    (0.246573096, -0.063274796, 0.252527381, -0.261363721, 0.466122399, 0.0),
                    (0.381547041, -0.291036933, 0.389778391, 0.287433182, 0.27758928, 0.0)
                ])
            ]
        ]
        with self.assertRaises(TypeError):
            self.__outp_layer.weights = new_weights

    def test_weights_test_negative_3(self):
        """ Веса слоя - это список списков NumPy-матриц (количество нейронов - количество входных
        карт - матрицы ядер свёртки). Проверить ситуацию, когда по всем размерам всё ок, но вот
        матрицы ядер свёртки - это не NumPy-матрицы, а обычные двумерные списки Python. """
        new_weights = [
            [
                [
                    (-0.454674414, -0.441725273, -0.486623893, -0.376976411, 0.367468698),
                    (-0.053292873, 0.326160682, 0.326991651, 0.202840349, -0.422132417),
                    (-0.445360747, -0.449640024, -0.406142867, -0.003760607, -0.482318478),
                    (-0.253001885, 0.102090174, 0.246324147, 0.481517294, -0.361479527),
                    (-0.450400576, 0.006689988, -0.333592, 0.426673298, -0.280534841),
                    (-0.065965359, -0.398088238, -0.490655182, 0.171313846, 0.264480646)
                ],
                [
                    (0.079794328, -0.19524951, 0.317091302, -0.459675767, -0.198357636),
                    (-0.480168326, -0.392917773, -0.23172113, -0.00792253, 0.070097674),
                    (0.405826162, 0.197388915, 0.4789901, 0.420279572, -0.159391308),
                    (0.372226375, -0.372530989, 0.145719222, 0.018017577, 0.251069434),
                    (0.217568815, -0.148776829, 0.001326967, -0.130171852, 0.369767726),
                    (-0.341117794, 0.145898972, -0.332775521, 0.483934177, -0.416705353)
                ],
                [
                    (-0.476924909, -0.269225488, -0.249753236, -0.442314854, -0.159383912),
                    (-0.323957971, 0.195592978, 0.422373795, 0.060914007, 0.062989159),
                    (0.292780167, 0.279683882, 0.444263032, -0.438587034, 0.135713465),
                    (0.377193973, 0.016155193, -0.459097708, 0.266688111, -0.220697964),
                    (-0.362538178, -0.011432353, -0.27093209, -0.248956626, 0.07696188),
                    (-0.047400263, -0.062470349, 0.078586347, 0.27625016, 0.18835347)
                ]
            ],
            [
                [
                    (-0.202863282, 0.28829226, 0.282718135, 0.096134406, 0.456977996),
                    (-0.274418228, -0.234425706, 0.05785365, -0.06490379, -0.377486742),
                    (-0.419559302, -0.143778663, -0.116099926, -0.474383738, 0.046602598),
                    (0.044930093, 0.247712139, 0.005803541, 0.250998176, 0.449352095),
                    (0.199603456, -0.07557929, 0.322262488, -0.359220075, 0.245747417),
                    (0.014741504, 0.238926459, 0.491132787, 0.276878266, -0.137662576)
                ],
                [
                    (0.490487156, 0.005511377, -0.014476584, 0.228535976, -0.393549441),
                    (0.189291725, -0.327867206, 0.092874804, -0.049892357, 0.279776564),
                    (-0.276009354, 0.290751897, 0.348271842, -0.377064422, 0.478562769),
                    (-0.343580366, 0.298695006, 0.286017776, -0.457108345, 0.238568862),
                    (-0.292281832, -0.46288513, 0.230249426, 0.288571429, 0.028275002),
                    (0.145991153, 0.404859449, 0.066038543, 0.156398111, 0.145153439)
                ],
                [
                    (0.463882371, -0.311133241, 0.372956677, -0.098991783, -0.049545014),
                    (-0.284782393, 0.431144666, 0.291606315, 0.498025137, 0.335957571),
                    (-0.204876622, -0.31305411, 0.417761697, -0.015632546, -0.003135778),
                    (0.034053238, -0.35497037, -0.44041787, -0.092747184, -0.109488222),
                    (-0.114606532, 0.069268646, -0.39206122, -0.045330931, 0.155447554),
                    (0.338865244, 0.113643134, -0.057939344, -0.379042147, 0.21078928)
                ]
            ],
            [
                [
                    (-0.299678495, -0.113090667, -0.18903115, -0.184299415, -0.371188011),
                    (-0.494101227, -0.258069743, -0.299069225, 0.273435785, -0.142228124),
                    (-0.000329091, -0.153832775, 0.395297859, -0.186692651, 0.353874482),
                    (-0.447242771, 0.018163554, -0.078206526, -0.266116927, -0.299481678),
                    (0.032140557, -0.283720287, -0.194573184, -0.186307706, -0.191749879),
                    (-0.183227743, 0.039593093, 0.455484617, 0.021098511, 0.098095268)
                ],
                [
                    (-0.311148519, -0.194404053, 0.323847546, 0.364637794, -0.280976444),
                    (0.188403093, -0.374352309, 0.269344625, 0.499948284, -0.276370449),
                    (-0.295358328, -0.24729578, -0.217795888, -0.335376398, 0.335477232),
                    (0.331628197, -0.209947528, -0.077432699, -0.136797804, -0.289596848),
                    (0.139455282, -0.180101284, 0.306369567, 0.15976188, -0.47032822),
                    (0.446516761, 0.33013828, -0.360802439, -0.47452184, -0.295809218)
                ],
                [
                    (0.369013813, 0.477380155, -0.452500277, 0.438185997, 0.426058596),
                    (-0.242282214, -0.260105689, 0.154901667, -0.028947964, 0.065422646),
                    (-0.253542557, -0.317212602, -0.432593688, -0.334732307, -0.192623597),
                    (-0.440837817, -0.356527346, 0.116265104, -0.126445104, -0.274360094),
                    (0.29171755, -0.276353739, 0.137749256, 0.118710131, -0.484571369),
                    (-0.322392575, -0.386873394, -0.361833835, -0.255350275, -0.349296533)
                ]
            ],
            [
                [
                    (-0.449460745, -0.253007887, -0.194399328, -0.275367064, -0.359070774),
                    (-0.34433586, -0.012106807, -0.129307274, -0.139861178, -0.136041697),
                    (-0.005309823, -0.196891443, -0.048109688, 0.272980185, 0.061122833),
                    (-0.421634952, 0.486388495, -0.229163475, 0.00103553, 0.476910662),
                    (0.29657942, 0.457293363, -0.167292721, 0.11759179, -0.21235073),
                    (-0.097914524, -0.160020185, -0.072404522, 0.160948139, -0.478466397)
                ],
                [
                    (-0.420607506, 0.172098881, -0.376769741, -0.366272162, -0.293564716),
                    (-0.464811374, -0.402434773, 0.109630806, 0.263349757, 0.129296024),
                    (-0.054035277, -0.067294919, -0.264539027, -0.332085643, -0.338287466),
                    (-0.268050896, 0.445170539, -0.407633996, -0.124971714, -0.0072076),
                    (-0.384147329, 0.419084917, -0.076962926, 0.187870538, 0.021116395),
                    (-0.112073712, 0.263373415, -0.085608985, -0.457872067, 0.006026119)
                ],
                [
                    (-0.035959159, 0.419720805, 0.124757543, 0.035578072, 0.189412826),
                    (-0.38675052, 0.452691094, -0.464881311, -0.408597675, 0.188096728),
                    (-0.023559184, -0.443554656, 0.364865831, -0.061112865, -0.116008117),
                    (0.358103596, -0.085526332, 0.014058369, -0.339390463, -0.16219448),
                    (-0.173262608, 0.046314698, -0.41004383, -0.165248266, 0.012242206),
                    (-0.099145536, 0.451810915, 0.328634, 0.340084647, 0.461833215)
                ]
            ],
            [
                [
                    (0.124252122, 0.292495015, -0.224113444, -0.256014028, -0.387348048),
                    (-0.341058309, -0.333722667, 0.048620384, -0.370189773, 0.422851122),
                    (0.224746715, -0.138544677, -0.159919879, 0.110663154, -0.258574362),
                    (0.070696506, 0.462299485, -0.447285126, 0.464142036, -0.160356366),
                    (0.429070791, 0.46824914, 0.344677839, 0.236996919, 0.412389438),
                    (-0.003488852, 0.119097804, -0.152228698, -0.271103595, -0.33506325)
                ],
                [
                    (-0.27142832, -0.186759268, 0.162263413, 0.234338668, 0.442739308),
                    (-0.232565198, 0.127096043, -0.478007937, 0.314343831, 0.139751638),
                    (-0.030116727, 0.449512681, -0.337397043, -0.439935018, 0.228024253),
                    (-0.043690428, -0.010719449, -0.444858394, -0.241143995, -0.149188489),
                    (-0.187198303, 0.095820806, -0.221517029, 0.219883989, 0.378959773),
                    (0.387755985, -0.367029968, 0.225137997, 0.312546061, 0.013971877)
                ],
                [
                    (-0.167213155, 0.419868757, -0.284917038, 0.02046365, -0.053330047),
                    (-0.357636875, 0.261632758, 0.230166954, 0.111422782, 0.314619794),
                    (-0.269418538, 0.15532752, 0.036454943, 0.40769268, 0.226733427),
                    (-0.1884218, 0.310495793, -0.236800472, -0.034481034, 0.052192425),
                    (0.246573096, -0.063274796, 0.252527381, -0.261363721, 0.466122399),
                    (0.381547041, -0.291036933, 0.389778391, 0.287433182, 0.27758928)
                ]
            ]
        ]
        with self.assertRaises(TypeError):
            self.__outp_layer.weights = new_weights

    def test_biases_test_negative_1(self):
        """ Смещения (biases) слоя - это обычный Python-список вещественных чисел, длина которого
        равна количеству нейронов в слое. А что, если мы попытаемся записать в biases список большей
        длины? """
        new_biases = [random.random() for ind in range(self.__number_of_neurons + 2)]
        with self.assertRaises(TypeError):
            self.__outp_layer.biases = new_biases

    def test_biases_test_negative_2(self):
        """ Смещения (biases) слоя - это обычный Python-список вещественных чисел, длина которого
        равна количеству нейронов в выходном слое. А что, если мы не все значения этого списка будут
        вещественными? """
        new_biases = [0.3, 2, 'a', -1, 0]
        with self.assertRaises(TypeError):
            self.__outp_layer.biases = new_biases

    def test_number_of_trainable_params(self):
        """ Проверить, что свойство number_of_trainable_params (количество обучаемых параметров
        слоя) возвращает правильное число. """
        self.assertEqual(self.__outp_layer.number_of_trainable_params,
                         (self.__input_map_size[0] * self.__input_map_size[1] \
                          * self.__number_of_input_maps + 1) * self.__number_of_neurons)

    def test_layer_id(self):
        """ Проверить, что идентификатор слоя установлен правильно, т.е. свойство layer_id
        возвращает именно то число, которое было установлено при создании этого слоя. """
        self.assertEqual(self.__outp_layer.layer_id, self.__layer_id)

    def test_calculate_outputs_test_positive_1(self):
        """ Проверить, что выходы (выходные карты) слоя рассчитываются правильно при подаче на вход
        заданных корректных входных сигналов (набора входных карт). """
        self.__outp_layer.weights = self.__weights_before_learning
        self.__outp_layer.biases = self.__biases_before_learning
        calculated_outputs = self.__outp_layer.calculate_outputs(self.__input_maps)
        self.assertEqual(len(calculated_outputs), self.__number_of_neurons,
                         msg = 'Target {0} != real {1}: Number of calculated outputs is '\
                         'incorrect!'.format(self.__number_of_neurons,
                                             len(calculated_outputs))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertAlmostEqual(
                calculated_outputs[neuron_ind], self.__target_real_outputs[neuron_ind],
                msg = 'Output of {0} neuron is incorrect!\n{1}'.format(integer_to_ordinal(neuron_ind+1),
                                                                       str(calculated_outputs[neuron_ind]))
                )

    def test_calculate_outputs_test_negative_1(self):
        """ Проверить ситуацию, когда входной сигнал некорректен - входные карты правильного
        размера, но их слишком много. """
        input_maps = [
            numpy.array([
                (-0.14062, 0.293809, 0.905852, -0.45878, 0.740724),
                (-0.68267, -0.09463, 0.614261, -0.50213, 0.565014),
                (0.076374, -0.7649, -0.30093, 0.471437, -0.32848),
                (-0.38347, 0.160011, -0.30884, 0.493158, -0.28132),
                (-0.64146, -0.92638, 0.867563, -0.10696, -0.05661),
                (0.422351, -0.06871, 0.186391, -0.49686, 0.870728)
            ]),
            numpy.array([
                (-0.20349, 0.031203, -0.12173, 0.743632, 0.328677),
                (-0.20938, 0.00954, 0.517926, 0.607911, 0.535574),
                (0.808547, 0.074892, -0.54315, -0.34995, 0.639988),
                (0.773657, -0.29811, -0.13906, -0.51, -0.00329),
                (-0.27878, 0.498802, -0.15015, 0.823873, 0.800871),
                (0.100963, 0.540328, -0.4175, -0.13177, 0.149454)
            ]),
            numpy.array([
                (-0.79188, 0.276618, -0.43735, -0.72712, -0.85333),
                (-0.63524, -0.39295, 0.667738, -0.7939, 0.728149),
                (-0.7309, 0.15348, -0.78023, -0.05637, -0.56361),
                (-0.02899, 0.209677, 0.162097, 0.481749, 0.270865),
                (-0.92895, 0.193228, -0.10883, 0.21654, -0.25176),
                (-0.62173, -0.15969, 0.700956, 0.87735, 0.450899)
            ]),
            numpy.array([
                (-0.79188, 0.276618, -0.43735, -0.72712, -0.85333),
                (-0.63524, -0.39295, 0.667738, -0.7939, 0.728149),
                (-0.7309, 0.15348, -0.78023, -0.05637, -0.56361),
                (-0.02899, 0.209677, 0.162097, 0.481749, 0.270865),
                (-0.92895, 0.193228, -0.10883, 0.21654, -0.25176),
                (-0.62173, -0.15969, 0.700956, 0.87735, 0.450899)
            ])
        ]
        with self.assertRaises(output_layer.EOutputLayerCalculating):
            self.__outp_layer.calculate_outputs(input_maps)

    def test_calculate_outputs_test_negative_2(self):
        """ Проверить ситуацию, когда входной сигнал некорректен - количество входных карт
        верное, но сами они неправильного размера. """
        input_maps = [
            numpy.array([
                (-0.14062, 0.293809, 0.905852, -0.45878, 0.740724, 0.0),
                (-0.68267, -0.09463, 0.614261, -0.50213, 0.565014, 0.0),
                (0.076374, -0.7649, -0.30093, 0.471437, -0.32848, 0.0),
                (-0.38347, 0.160011, -0.30884, 0.493158, -0.28132, 0.0),
                (-0.64146, -0.92638, 0.867563, -0.10696, -0.05661, 0.0),
                (0.422351, -0.06871, 0.186391, -0.49686, 0.870728, 0.0)
            ]),
            numpy.array([
                (-0.20349, 0.031203, -0.12173, 0.743632, 0.328677, 0.0),
                (-0.20938, 0.00954, 0.517926, 0.607911, 0.535574, 0.0),
                (0.808547, 0.074892, -0.54315, -0.34995, 0.639988, 0.0),
                (0.773657, -0.29811, -0.13906, -0.51, -0.00329, 0.0),
                (-0.27878, 0.498802, -0.15015, 0.823873, 0.800871, 0.0),
                (0.100963, 0.540328, -0.4175, -0.13177, 0.149454, 0.0)
            ]),
            numpy.array([
                (-0.79188, 0.276618, -0.43735, -0.72712, -0.85333, 0.0),
                (-0.63524, -0.39295, 0.667738, -0.7939, 0.728149, 0.0),
                (-0.7309, 0.15348, -0.78023, -0.05637, -0.56361, 0.0),
                (-0.02899, 0.209677, 0.162097, 0.481749, 0.270865, 0.0),
                (-0.92895, 0.193228, -0.10883, 0.21654, -0.25176, 0.0),
                (-0.62173, -0.15969, 0.700956, 0.87735, 0.450899, 0.0)
            ])
        ]
        with self.assertRaises(output_layer.EOutputLayerCalculating):
            self.__outp_layer.calculate_outputs(input_maps)

    def test_calculate_outputs_test_negative_3(self):
        """ Проверить ситуацию, когда входной сигнал - ничто. """
        with self.assertRaises(output_layer.EOutputLayerCalculating):
            self.__outp_layer.calculate_outputs(None)

    def test_calculate_gradient_test_positive_1(self):
        """ Проверить, как расчитываются градиенты нейронов слоя, когда желаемые выходные сигналы
        нейронной сети заданы корректно и являются Python-массивом вещественных чисел. """
        self.__outp_layer.weights = self.__weights_before_learning
        self.__outp_layer.biases = self.__biases_before_learning
        self.__outp_layer.calculate_outputs(self.__input_maps)
        self.__outp_layer.calculate_gradient(self.__target_target_outputs)
        calculated_gradients = self.__outp_layer.gradients
        self.assertEqual(len(calculated_gradients), self.__number_of_neurons,
                         msg = 'Target {0} != real {1}: Number of calculated outputs is '\
                         'incorrect!'.format(self.__number_of_neurons,
                                             len(calculated_gradients))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertAlmostEqual(
                calculated_gradients[neuron_ind],
                self.__target_gradients[neuron_ind],
                msg = 'Gradient of {0} neuron is incorrect!\n{1}'.format(
                    integer_to_ordinal(neuron_ind+1), str(calculated_gradients[neuron_ind]))
            )

    def test_calculate_gradient_test_positive_2(self):
        """ Проверить, как расчитываются градиенты нейронов слоя, когда желаемые выходные сигналы
        нейронной сети заданы корректно и являются одномерным NumPy-массивом вещественных чисел. """
        self.__outp_layer.weights = self.__weights_before_learning
        self.__outp_layer.biases = self.__biases_before_learning
        self.__outp_layer.calculate_outputs(self.__input_maps)
        self.__outp_layer.calculate_gradient(numpy.array(self.__target_target_outputs))
        calculated_gradients = self.__outp_layer.gradients
        self.assertEqual(len(calculated_gradients), self.__number_of_neurons,
                         msg='Target {0} != real {1}: Number of calculated outputs is ' \
                             'incorrect!'.format(self.__number_of_neurons,
                                                 len(calculated_gradients))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertAlmostEqual(
                calculated_gradients[neuron_ind],
                self.__target_gradients[neuron_ind],
                msg='Gradient of {0} neuron is incorrect!\n{1}'.format(
                    integer_to_ordinal(neuron_ind + 1), str(calculated_gradients[neuron_ind]))
            )

    def test_calculate_gradient_test_negative_1(self):
        """ Проверить метод расчёта градиентов нейронов слоя, когда вместо желаемых выходных
        сигналов нейронной сети задано ничто. """
        with self.assertRaises(output_layer.EOutputLayerGradient):
            self.__outp_layer.calculate_gradient(None)

    def test_calculate_gradient_test_negative_2(self):
        """ Проверить метод расчёта градиентов нейронов слоя, когда размер массива с желаемыми
        выходными сигналами нейронной сети задан верно, но вот значения этого массива иногда
        являются фигнёй. """
        target_outputs = [random.random() for neuron_ind in range(self.__number_of_neurons)]
        target_outputs[0] = 'a'
        with self.assertRaises(output_layer.EOutputLayerGradient):
            self.__outp_layer.calculate_gradient(target_outputs)

    def test_calculate_gradient_test_negative_3(self):
        """ Проверить метод расчёта градиентов нейронов слоя, когда размер массива с желаемыми
        выходными сигналами нейронной сети слишком велик. """
        target_outputs = [random.random() for neuron_ind in range(self.__number_of_neurons+2)]
        with self.assertRaises(output_layer.EOutputLayerGradient):
            self.__outp_layer.calculate_gradient(target_outputs)

    def test_calculate_gradient_test_negative_4(self):
        """ Проверить метод расчёта градиентов нейронов слоя, когда размер массива с желаемыми
        выходными сигналами нейронной сети слишком велик, а сам массив при этом является
        одномерным NumPy-массивом. """
        target_outputs = numpy.array([random.random()
                                      for neuron_ind in range(self.__number_of_neurons+2)])
        with self.assertRaises(output_layer.EOutputLayerGradient):
            self.__outp_layer.calculate_gradient(target_outputs)

    def test_update_weights_and_biases_test_positive_1(self):
        """ Проверить, как обновляются веса и смещения слоя с заданным коэффициентом скорости
        обучения после прямого распространения сигнала и обратного распространения ошибки (т.е.
        выходы и градиенты слоя уже благополучно расчитаны). """
        self.__outp_layer.weights = self.__weights_before_learning
        self.__outp_layer.biases = self.__biases_before_learning
        self.__outp_layer.calculate_outputs(self.__input_maps)
        self.__outp_layer.calculate_gradient(self.__target_target_outputs)
        self.__outp_layer.update_weights_and_biases(self.__learning_rate, self.__input_maps)
        new_weights = self.__outp_layer.weights
        self.assertEqual(len(new_weights), self.__number_of_neurons,
                         msg = 'Target {0} != real {1}: number of neurons with updated '\
                         'convolution kernels is incorrect!'.format(self.__number_of_neurons,
                                                                    len(new_weights))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertEqual(len(new_weights[neuron_ind]), self.__number_of_input_maps,
                             msg = 'Target {0} != real {1}: number of updated convolution kernels '\
                             'of {2} neuron is incorrect!'.format(
                                 self.__number_of_input_maps, len(new_weights[neuron_ind]),
                                 integer_to_ordinal(neuron_ind + 1))
                             )
            for inp_ind in range(self.__number_of_input_maps):
                self.assertIsInstance(new_weights[neuron_ind][inp_ind], numpy.ndarray,
                                      msg = 'Type of {0} convolution kernel of {1} neuron is '\
                                      'incorrect!'.format(integer_to_ordinal(inp_ind + 1),
                                                          integer_to_ordinal(neuron_ind + 1))
                                      )
                self.assertEqual(new_weights[neuron_ind][inp_ind].shape, self.__input_map_size,
                                 msg = 'Sizes of {0} convolution kernel of {1} neuron are '\
                                 'incorrect!'.format(integer_to_ordinal(inp_ind+1),
                                                     integer_to_ordinal(neuron_ind+1))
                                 )
                for ind in numpy.ndindex(self.__input_map_size):
                    self.assertAlmostEqual(
                        new_weights[neuron_ind][inp_ind][ind],
                        self.__weights_after_learning[neuron_ind][inp_ind][ind],
                        msg = 'Values of {0} convolution kernel of {1} neuron are '\
                        'incorrect!\n{2}'.format(
                            integer_to_ordinal(inp_ind+1), integer_to_ordinal(neuron_ind+1),
                            str(new_weights[neuron_ind][inp_ind]))
                    )
        new_biases = self.__outp_layer.biases
        self.assertEqual(len(new_biases), self.__number_of_neurons,
                         msg = 'Target {0} != real {1}: number of neurons with updated '\
                         'biases is incorrect!'.format(self.__number_of_neurons,
                                                       len(new_biases))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertIsInstance(new_biases[neuron_ind], float,
                                  msg = 'Type of {0} neuron\'s bias is incorrect'.format(
                                      integer_to_ordinal(neuron_ind+1))
                                  )
            self.assertAlmostEqual(new_biases[neuron_ind],
                                   self.__biases_after_learning[neuron_ind],
                                   msg = 'Target {0} != real {1}: value of {2} neuron\'s bias'\
                                   ' is incorrect'.format(self.__biases_after_learning[neuron_ind],
                                                          new_biases[neuron_ind],
                                                          integer_to_ordinal(neuron_ind+1))
                                   )

    def test_update_weights_and_biases_test_positive_2(self):
        """ Проверить, как обновляются веса и смещения слоя с нулевым коэффициентом скорости
        обучения после прямого распространения сигнала и обратного распространения ошибки (т.е.
        выходы и градиенты слоя уже благополучно расчитаны). Правильный ответ - не меняются. """
        self.__outp_layer.weights = self.__weights_before_learning
        self.__outp_layer.biases = self.__biases_before_learning
        self.__outp_layer.calculate_outputs(self.__input_maps)
        self.__outp_layer.calculate_gradient(self.__target_target_outputs)
        self.__outp_layer.update_weights_and_biases(0.0, self.__input_maps)
        new_weights = self.__outp_layer.weights
        self.assertEqual(len(new_weights), self.__number_of_neurons,
                         msg='Target {0} != real {1}: number of neurons with updated ' \
                             'convolution kernels is incorrect!'.format(self.__number_of_neurons,
                                                                        len(new_weights))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertEqual(len(new_weights[neuron_ind]), self.__number_of_input_maps,
                             msg='Target {0} != real {1}: number of updated convolution kernels ' \
                                 'of {2} neuron is incorrect!'.format(
                                 self.__number_of_input_maps, len(new_weights[neuron_ind]),
                                 integer_to_ordinal(neuron_ind + 1))
                             )
            for inp_ind in range(self.__number_of_input_maps):
                self.assertIsInstance(new_weights[neuron_ind][inp_ind], numpy.ndarray,
                                      msg='Type of {0} convolution kernel of {1} neuron is ' \
                                          'incorrect!'.format(integer_to_ordinal(inp_ind + 1),
                                                              integer_to_ordinal(neuron_ind + 1))
                                      )
                self.assertEqual(new_weights[neuron_ind][inp_ind].shape, self.__input_map_size,
                                 msg='Sizes of {0} convolution kernel of {1} neuron are ' \
                                     'incorrect!'.format(integer_to_ordinal(inp_ind + 1),
                                                         integer_to_ordinal(neuron_ind + 1))
                                 )
                for ind in numpy.ndindex(self.__input_map_size):
                    self.assertAlmostEqual(
                        new_weights[neuron_ind][inp_ind][ind],
                        self.__weights_before_learning[neuron_ind][inp_ind][ind],
                        msg='Values of {0} convolution kernel of {1} neuron are ' \
                            'incorrect!\n{2}'.format(
                            integer_to_ordinal(inp_ind + 1), integer_to_ordinal(neuron_ind + 1),
                            str(new_weights[neuron_ind][inp_ind]))
                    )
        new_biases = self.__outp_layer.biases
        self.assertEqual(len(new_biases), self.__number_of_neurons,
                         msg='Target {0} != real {1}: number of neurons with updated ' \
                             'biases is incorrect!'.format(self.__number_of_neurons,
                                                           len(new_biases))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertIsInstance(new_biases[neuron_ind], float,
                                  msg='Type of {0} neuron\'s bias is incorrect'.format(
                                      integer_to_ordinal(neuron_ind + 1))
                                  )
            self.assertAlmostEqual(new_biases[neuron_ind],
                                   self.__biases_before_learning[neuron_ind],
                                   msg='Target {0} != real {1}: value of {2} neuron\'s bias' \
                                       ' is incorrect'.format(self.__biases_before_learning[neuron_ind],
                                                              new_biases[neuron_ind],
                                                              integer_to_ordinal(neuron_ind + 1))
                                   )

    def test_update_weights_and_biases_test_positive_3(self):
        """ Проверить, как обновляются веса и смещения слоя с пустым (None) коэффициентом скорости
        обучения после прямого распространения сигнала и обратного распространения ошибки (т.е.
        выходы и градиенты слоя уже благополучно расчитаны). Правильный ответ - не меняются,
        поскольку пустой коэффициент скорости обучения считается нулевым. """
        self.__outp_layer.weights = self.__weights_before_learning
        self.__outp_layer.biases = self.__biases_before_learning
        self.__outp_layer.calculate_outputs(self.__input_maps)
        self.__outp_layer.calculate_gradient(self.__target_target_outputs)
        self.__outp_layer.update_weights_and_biases(None, self.__input_maps)
        new_weights = self.__outp_layer.weights
        self.assertEqual(len(new_weights), self.__number_of_neurons,
                         msg='Target {0} != real {1}: number of neurons with updated ' \
                             'convolution kernels is incorrect!'.format(self.__number_of_neurons,
                                                                        len(new_weights))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertEqual(len(new_weights[neuron_ind]), self.__number_of_input_maps,
                             msg='Target {0} != real {1}: number of updated convolution kernels ' \
                                 'of {2} neuron is incorrect!'.format(
                                 self.__number_of_input_maps, len(new_weights[neuron_ind]),
                                 integer_to_ordinal(neuron_ind + 1))
                             )
            for inp_ind in range(self.__number_of_input_maps):
                self.assertIsInstance(new_weights[neuron_ind][inp_ind], numpy.ndarray,
                                      msg='Type of {0} convolution kernel of {1} neuron is ' \
                                          'incorrect!'.format(integer_to_ordinal(inp_ind + 1),
                                                              integer_to_ordinal(neuron_ind + 1))
                                      )
                self.assertEqual(new_weights[neuron_ind][inp_ind].shape, self.__input_map_size,
                                 msg='Sizes of {0} convolution kernel of {1} neuron are ' \
                                     'incorrect!'.format(integer_to_ordinal(inp_ind + 1),
                                                         integer_to_ordinal(neuron_ind + 1))
                                 )
                for ind in numpy.ndindex(self.__input_map_size):
                    self.assertAlmostEqual(
                        new_weights[neuron_ind][inp_ind][ind],
                        self.__weights_before_learning[neuron_ind][inp_ind][ind],
                        msg='Values of {0} convolution kernel of {1} neuron are ' \
                            'incorrect!\n{2}'.format(
                            integer_to_ordinal(inp_ind + 1), integer_to_ordinal(neuron_ind + 1),
                            str(new_weights[neuron_ind][inp_ind]))
                    )
        new_biases = self.__outp_layer.biases
        self.assertEqual(len(new_biases), self.__number_of_neurons,
                         msg='Target {0} != real {1}: number of neurons with updated ' \
                             'biases is incorrect!'.format(self.__number_of_neurons,
                                                           len(new_biases))
                         )
        for neuron_ind in range(self.__number_of_neurons):
            self.assertIsInstance(new_biases[neuron_ind], float,
                                  msg='Type of {0} neuron\'s bias is incorrect'.format(
                                      integer_to_ordinal(neuron_ind + 1))
                                  )
            self.assertAlmostEqual(new_biases[neuron_ind],
                                   self.__biases_before_learning[neuron_ind],
                                   msg='Target {0} != real {1}: value of {2} neuron\'s bias' \
                                       ' is incorrect'.format(self.__biases_before_learning[neuron_ind],
                                                              new_biases[neuron_ind],
                                                              integer_to_ordinal(neuron_ind + 1))
                                   )

    def test_update_weights_and_biases_test_negative_1(self):
        """ Что делать, когда мы хотим обучить слой (обновить веса и смещения) после прямого и
        обратного прохода, а входной сигнал для слоя некорректен - слишком много входных карт. """
        input_maps = [
            numpy.array([
                (-0.14062, 0.293809, 0.905852, -0.45878, 0.740724),
                (-0.68267, -0.09463, 0.614261, -0.50213, 0.565014),
                (0.076374, -0.7649, -0.30093, 0.471437, -0.32848),
                (-0.38347, 0.160011, -0.30884, 0.493158, -0.28132),
                (-0.64146, -0.92638, 0.867563, -0.10696, -0.05661),
                (0.422351, -0.06871, 0.186391, -0.49686, 0.870728)
            ]),
            numpy.array([
                (-0.20349, 0.031203, -0.12173, 0.743632, 0.328677),
                (-0.20938, 0.00954, 0.517926, 0.607911, 0.535574),
                (0.808547, 0.074892, -0.54315, -0.34995, 0.639988),
                (0.773657, -0.29811, -0.13906, -0.51, -0.00329),
                (-0.27878, 0.498802, -0.15015, 0.823873, 0.800871),
                (0.100963, 0.540328, -0.4175, -0.13177, 0.149454)
            ]),
            numpy.array([
                (-0.79188, 0.276618, -0.43735, -0.72712, -0.85333),
                (-0.63524, -0.39295, 0.667738, -0.7939, 0.728149),
                (-0.7309, 0.15348, -0.78023, -0.05637, -0.56361),
                (-0.02899, 0.209677, 0.162097, 0.481749, 0.270865),
                (-0.92895, 0.193228, -0.10883, 0.21654, -0.25176),
                (-0.62173, -0.15969, 0.700956, 0.87735, 0.450899)
            ]),
            numpy.array([
                (-0.79188, 0.276618, -0.43735, -0.72712, -0.85333),
                (-0.63524, -0.39295, 0.667738, -0.7939, 0.728149),
                (-0.7309, 0.15348, -0.78023, -0.05637, -0.56361),
                (-0.02899, 0.209677, 0.162097, 0.481749, 0.270865),
                (-0.92895, 0.193228, -0.10883, 0.21654, -0.25176),
                (-0.62173, -0.15969, 0.700956, 0.87735, 0.450899)
            ])
        ]
        with self.assertRaises(output_layer.EOutputLayerCalculating):
            self.__outp_layer.update_weights_and_biases(self.__learning_rate, input_maps)

    def test_update_weights_and_biases_test_negative_2(self):
        """ Что делать, когда мы хотим обучить слой (обновить веса и смещения) после прямого и
        обратного прохода, а входной сигнал для слоя некорректен - входных карт столько, сколько
        нужно, но они не такого размера. """
        input_maps = [
            numpy.array([
                (-0.14062, 0.293809, 0.905852, -0.45878, 0.740724, 0.0),
                (-0.68267, -0.09463, 0.614261, -0.50213, 0.565014, 0.0),
                (0.076374, -0.7649, -0.30093, 0.471437, -0.32848, 0.0),
                (-0.38347, 0.160011, -0.30884, 0.493158, -0.28132, 0.0),
                (-0.64146, -0.92638, 0.867563, -0.10696, -0.05661, 0.0),
                (0.422351, -0.06871, 0.186391, -0.49686, 0.870728, 0.0)
            ]),
            numpy.array([
                (-0.20349, 0.031203, -0.12173, 0.743632, 0.328677, 0.0),
                (-0.20938, 0.00954, 0.517926, 0.607911, 0.535574, 0.0),
                (0.808547, 0.074892, -0.54315, -0.34995, 0.639988, 0.0),
                (0.773657, -0.29811, -0.13906, -0.51, -0.00329, 0.0),
                (-0.27878, 0.498802, -0.15015, 0.823873, 0.800871, 0.0),
                (0.100963, 0.540328, -0.4175, -0.13177, 0.149454, 0.0)
            ]),
            numpy.array([
                (-0.79188, 0.276618, -0.43735, -0.72712, -0.85333, 0.0),
                (-0.63524, -0.39295, 0.667738, -0.7939, 0.728149, 0.0),
                (-0.7309, 0.15348, -0.78023, -0.05637, -0.56361, 0.0),
                (-0.02899, 0.209677, 0.162097, 0.481749, 0.270865, 0.0),
                (-0.92895, 0.193228, -0.10883, 0.21654, -0.25176, 0.0),
                (-0.62173, -0.15969, 0.700956, 0.87735, 0.450899, 0.0)
            ])
        ]
        with self.assertRaises(output_layer.EOutputLayerCalculating):
            self.__outp_layer.update_weights_and_biases(self.__learning_rate, input_maps)

    def test_update_weights_and_biases_test_negative_3(self):
        """ Что делать, когда мы хотим обучить слой (обновить веса и смещения) после прямого и
        обратного прохода, а входной сигнал для слоя попросту пуст, ничто, None. """
        with self.assertRaises(output_layer.EOutputLayerCalculating):
            self.__outp_layer.update_weights_and_biases(self.__learning_rate, None)


if __name__ == '__main__':
    #unittest.main(verbosity=2)
    unittest.main()
